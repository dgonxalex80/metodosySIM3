---
title: <span style="color:#034a94"> **Análisis de correlación**</span>
author: "Métodos y Simulación Estadística"
output: html_document
css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)

c1="#FF7F00"
c2="#FEB0C6"
c3="#034A94"
c4="#686868"
#-------------------------------------------------------------------------
library(tidyverse)
# install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)


#install.packages("devtools") # solo una vez
# devtools::install_github("dgonxalex80/paqueteMET") # descarga paqueteDEG
library(paqueteMET) # activa paqueteMET
data("biomasa") # carga la base biomasa

gen.corr.data<- function(rho,n){
x <- rnorm(n)
z <- rnorm(n)
y<- rho*x + sqrt(1-rho^2)*z
result <-cbind(y,x)
return(result)
}
#-------------------------------------------------------------------------
library(ggplot2)
library(patchwork)
Theme1= theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12))
#------------------------------------------------------------------------
Theme2= theme(
        #axis.text.x = element_blank(),
        #axis.text.y = element_blank(),
        #axis.ticks = element_blank(),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11))

data(biomasa)
biomasa38=biomasa[,3:8]
#------------------------------------------------------------------------
# Fijamos semilla
set.seed(20)
# Generamos datos aleatorios para la variable X
X <- sample(c("Si", "No"), 100, replace = TRUE)
# "No" "Si" "Si" "No"  "No" "Si" "No" "Si" "No" "No"

# Generamos datos aleatorios para la variable Y
Y <- sample(c("Europa", "America", "Africa"), 100, replace = TRUE)
# "Europa" "Africa"  "Africa"  "Europa"  "Africa" 
# "Europa" "Europa"  "Europa"  "America" "America"

tabla <- table(X, Y)



```

</br></br>

# **¿Qué es el análisis de correlación?**

</br>

El análisis de correlación es una técnica estadística que se puede usar para describir el grado de relación entre un par de variables cuantitativas. Para este análisis se dispone de una variable $Y$, que se supondrá que está relacionada con otra variable $X$, a partir de una muestra de $n$ pares de observaciones, es decir:

</br>

```{r, echo=FALSE, out.width="70%", fig.align = "center"}
knitr::include_graphics("img/correlacion1.png")
```

</br></br>

### **Ejemplos** :

* ¿Existe relación entre la inversión en publicidad de una empresa y sus ventas mensuales?

* ¿El número de metros cuadrados en una casa está relacionado con su costo de venta?

* ¿Existe relación entre los kilómetros por galón consumidos y el peso del auto?

* ¿Hay relación entre el número de horas que estudian los alumnos para un examen y la calificación que obtienen?

* ¿Qué relación existe entre el peso y la estatura de los estudiantes?

* ¿Existe relación entre la tasa de desempleo y la tasa de homicidios?

* ¿Hay relación entre la cantidad de medidas preventivas de tránsito y el número de accidentes de tránsito?

* ¿Son fuertes o débiles estas asociaciones? ¿Son directas o indirectas?

</br></br>

**Entre las principales herramientas del análisis de correlación se encuentran:**

* **Gráficos de dispersión**: “Representación gráfica simultanea del par de variables estudiadas”.

* **Coeficiente de correlación**: “Indicador que mide la fuerza de la relación lineal entre un par de variables”.


</br></br>

## **Gráfico de dispersión** 

</br>

Es un gráfico en el cual se representan las parejas ($X,Y$) de las variables observadas. La forma que toman los puntos, ilustra acerca de la posible asociación existe entre las variables.


</br>

<center>

```{r, echo=FALSE}
muestra1<-gen.corr.data(0.8,200)
muestra1<-as.data.frame(muestra1)


p1=ggplot(muestra1, aes(x, y)) + 
         geom_point() + Theme1+
         labs(title = "", y= "y", x= " ") +
         annotate("text", x=-3.3, y=3,size=4, label= "(a)")


muestra2<-gen.corr.data(-0.7,200)
muestra2<-as.data.frame(muestra2)

p2=ggplot(muestra2, aes(x, y)) + 
          geom_point() + Theme1+
          labs(title = "", y= " ", x= " ")+
          annotate("text", x=-3, y=3,size=4, label= "(b)")

muestra3<-gen.corr.data(0,200)
muestra3<-as.data.frame(muestra3)

p3=ggplot(muestra3, aes(x, y)) +  
          geom_point() + Theme1+
          labs(title = "", y= "y", x= "x")+
          annotate("text", x=-3, y=3,size=4, label= "(c)")



x=seq(-1, 1, 0.01)
y=x^2+rnorm(201, 0,0.1)
muestra5<-data.frame(x,y)

  
p5=ggplot(muestra5, aes(x, y)) + 
          geom_point() + Theme1+
          labs(title = "", y= " ", x= "x")+ 
          annotate("text", x=-1.2, y=1.2,size=4, label= "(d)")



(p1+p2)/(p3+p5)
```

</center>

Figura 1: Gráfico de dispersión y relaciones entre variables.

</br>

a. Relación lineal positiva (directa o creciente)
b. Relación lineal negativa (indirecta o decreciente)
c. Relación no lineal
d, No relación lineal

</br></br>

### **Ejemplo**:


 Identificar la posible relación lineal observada entre las variables:

*  $X$ : Cantidad de horas trabajadas en una empresa.
*  $Y$ : Cantidad de unidades producidas en la empresa.

<center>  

</br>

```{r, echo=FALSE}
data7=data.frame(x = c( 72, 75, 77, 78 ,79, 80, 80, 82, 83, 84 ,85),
                 y = c(301,305,315,312,312,310,315,316,315,320,317))

ggplot(data7, aes(x, y)) + 
          geom_point(size=2, colour=c1 ) + Theme2 +
          labs(title = "", 
               y= "Cantidad de unidades producidas", 
               x= "Cantidad de horas trabajadas")
```

</center>

Figura 2: Diagrama de dispersión entre las horas trabajadas y las unidades producidas en una empresa.

</br></br>

De acuerdo con el gráfico de dispersión de la figura 2, se observa una falta de relación lineal entre las variables cantidad de horas trabajadas en una empresa y la cantidad de unidades producidas en la empresa.

</br></br>

### **Ejemplo**:

Identificar la posible relación lineal observada entre las variables:

* $X$ : Tiempo  de la duración de una conferencia (en minutos).
* $Y$ : Índice de la capacidad de atención en la conferencia  (1: Poca,..., 10: Mucha).



Figura 3: Diagrama de dispersión entre el tiempo de duración de una conferencia y el índice de capacidad de atención en la misma.


</br></br>

## **Coeficiente de correlación**

Es una medida de la magnitud de la *asociación lineal** entre dos variables. Indica si los puntos tienen una tendencia a disponerse alineadamente y es útil para determinar si hay relación lineal entre las variables. El coeficiente de correlación presenta las siguientes características:

</br>

* Sólo toma valores entre $-1$ y $1$.
* Cuanto más cerca esté de $1$ o $-1$ mejor será el grado de relación lineal. Siempre y cuando no existan observaciones anómalas.


</br></br>

<center>

```{r, echo=FALSE, out.width="100%", fig.align = "center"}
knitr::include_graphics("img/correlacion2.png")
```

</center>

</br></br>

Un valor cercano a 1 indica asociación directa o positiva y un valor cercano a -1 indica asociación inversa o negativa. Si el valor es cercano a 0 indica una asociación débil.

* Se denota con la letra $r$ y su fórmula de cálculo es la siguiente:


$$r = \dfrac{n \Bigg(\displaystyle\sum_{i=1}^{n} x_{i}y_{i} \Bigg) \Bigg(\displaystyle\sum_{i=1}^{n} x_{i} \Bigg) \Bigg(\displaystyle\sum_{i=1}^{n} y_{i}\Bigg)}{
{\sqrt{n \Bigg(\displaystyle\sum_{i=1}^{n} x_{i}^{2} \Bigg) - \Bigg(\displaystyle\sum_{i=1}^{n} x_{i} \Bigg)^{2}} } {\sqrt{n \Bigg(\displaystyle\sum_{i=1}^{n} y_{i}^{2} \Bigg) - \Bigg(\displaystyle\sum_{i=1}^{n} y_{i} \Bigg)^{2}}}}$$

$$r = \dfrac{cov(xy)}{\sqrt{s_{x}^{2}\hspace{0.1cm} s_{y}^{2}}}$$

</br>

Este indicador fué propuesto por Karl Pearson por lo que se conoce como **coeficiente de correlación de Pearson** y exige que las variables $X$ y $Y$ sean variables cuantitavas en escala de intervalo o de razón y normalidad de las variables.


Los valores obtenidos del coeficiente de correlación permiten clasificar la relación lineal entre las variables de la siguiente forma:

</br></br>

| Coeficiente de corelación  | Relación lineal             |
|:--------------------------:|:---------------------------:|
| $0.8 \leq r < 1.0$         |  Positiva fuerte            |
| $0.3 \leq r < 0.8$         |  Positiva debil             |
| $-0.3 < r < 3$             |  No existe                  |
| $-0.8 < r \leq -0.3$       |  Negativa debil             |
| $-1.0 \leq r \leq -0.8$    |  Negativa fuerte            |

Tabla 1: Clasificación de la relación lineal entre variables por medio del coeficiente de correlación.

</br></br>


```{r, echo=FALSE, out.width="100%", fig.align = "center"}
knitr::include_graphics("img/Rho1.png")
```

</br>

```{r, echo=FALSE, out.width="100%", fig.align = "center"}
knitr::include_graphics("img/Rho2.png")
```

</br></br>

### **Ejemplo**: 

Se cuenta con la información de una muestra aleatoria de 6 pueblos del departamento, donde se observaron las variables número de policías y número de delitos
registrados durante el mes pasado, la información obtenida se presenta a continuación:

Mediante el coeficiente de correlación identificar el tipo de relación que pueda existir entre estas dos variables.

Sea $X$ la variable que representa el número de policías y sea $Y$ la variable que representa el número de delitos. Para construir el coeficiente se requieren las sumatorias de $x_{i}$, $y_{i}$, $x_{i}^{2}$, $y_{i}^{2}$ y de $x_{i}y_{i}$

</br>

<pre>
x=c(15,   17,   25,   27,   17,   12)
y=c(17,   13,    5,    7,    7,   21)

n           #    6
sum(x)      #  113 
sum(y)      #   70
sum(x^2)    # 2301
sum(y^2)    # 1022
sum(x*y)    # 1161

cor(x,y)    # [1] -0.8351746
</pre>

</br>


$$\widehat{\rho_{_{x,y}}}=r=\dfrac{6 (1161)-(113)(70)}{\sqrt{6(2301)-(113)^2}\sqrt{6(1022)-(70)^2}} = -0.80352$$

</br></br>

Por lo tanto, el resultado obtenido del coeficiente de correlación $r = −0.8352$, se busca en la tabla 1, y se observa que existe una **asociación lineal negativa y fuerte** entre el número de policías y el número de delitos, es decir que entre más policías en un pueblo menor será el número de delitos en los pueblos.

</br></br>

## **Pruebas de hipótesis sobre $\rho$**

Es importante verificar si de $\rho$ es igual a cero o se puede considerar diferente de cero, a partir de la muestra de estudio. Para ello se utiliza un estadístico de prueba con distribución t-Studen con $v=n-2$ grados de libertad


$Ho: \rho =0$
$Ha: \rho \neq 0$

Estadístico de prueba

$$U = \dfrac{r \sqrt{n-2}}{\sqrt{1-r^{2}}} \sim t_{v:n-2}$$
<pre>
x=c(15,   17,   25,   27,   17,   12)
y=c(17,   13,    5,    7,    7,   21)

r=cor(x,y)
r*sqrt(6-2)/sqrt(1-r^2)              # [1] -3.037082

cor.test(x,y, method = "pearson")

Pearson's product-moment correlation

data:  x and y
t = -3.0371, df = 4, p-value = 0.03851
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.98148791 -0.07328662
sample estimates:
       cor 
-0.8351746 
</pre>

</br>

Suponiendo que el valor p obtenido es pequeño, se concluye que $\rho \neq 0$


</br></br>

En caso de variables no normales, con presencia de datos atípicos o procedentes de variables cualitativas que son cuantificadas a través de escalas de intervalos, se recomienda el uso del **coeficiente de correlación de Spearman**

</br></br>

## **Otros indicadores de correlación**

</br>

**Coeficiente de correlación de Spearman**

Se considera como un coeficiente no paramétrico ( no requiere verificación de supuestos), propuesto por Charles Spearman y se basa en los rangos obtenidos para las variables X y Y. 

</br></br>

### **Nota**  
Los rangos se optienen al ordenar los datos y asignarles a cada valor el número del orden correspondiente ($1,2,3,4,5...n$) $R_{i}(x)$ y $R_{i}(y)$


</br>

$$\gamma_{s} = \dfrac{ \sum_{i=1}^{n}\Big[\big(  R_{i}(x) - \overline{R}(x)\big) \Big]}{\sqrt{\Bigg[ \sum_{i=1}^{n} \Big(R_{i}(x) - \overline{R}(x)\Big)^{2} \Bigg] \Bigg[ \sum_{i=1}^{n} \Big(R_{i}(y) - \overline{R}(y)\Big)^{2} \Bigg]}}$$

</br></br>


### **Nota**

</br>

Para el caso de variables cualitativas existen varios indicadores para medir el grado de asociación entre ellas como son:

* **Phi**, **Coeficiente de contingencia**, **V de Cramer**, **Lambda**,  **Kappa** : para tablas de contingencia con variables cualitativas en escala nominal.

* **Gamma**, **Tau b de Kendall**, **Tau c de Kendal**, **D de Somers**  : para variables cualitativas en escala ordinal

* **Eta** : para tablas con variables de intervalo y nominal 


</br></br>


### **Código R**


```{r}
library(paqueteMET)
data(biomasa) # data contenida en  paqueteMET
head(biomasa) # primeros 6 registros de la data
cor(biomasa[,3:8]) %>%  # matriz de correlaciones 
  round(.,3      )

```
</br></br>

### **Nota**

</br>

* Los resultados se presenta como matriz simetrica que tiene identicos valores arriba y debajo de la diagonal. ($\rho_{ij} = \rho_{ji}$)
* Los valores de la diagonal son unos, debido a que $Cor(x,x)=1$
* Existen relaciones positivas y negativas, fuertes y medias


</br></br>

```{r, message=FALSE, warning=FALSE}
library(GGally)
ggpairs(biomasa[,5:8], title="Biomasa") 
```

</br>

En esta matriz gráfica ademas de los diagramas de puntos que permiten visualizar el tipo de relación lineal entre las variables, permite visualizar la  distribución de cada variable, el valor de la correlación entre cada par de variables y su significancia sobre la prueba de hipótesis $Ho: \rho =0$ frente a $Ha: \rho \neq 0$.

En este caso todos los valores obtenidos son significativamente diferententes de cero.

</br></br>

Para el caso de variables cualitativas podemos utilizar los coeficientes $Phi$ o el de $Cramer$, a través de una tabla de contingencia o de doble entrada, por ejemplo:

</br>

<center>
```{r}
tabla = c(80,9,30,21) %>% 
           matrix(., nrow = 2) 
colnames(tabla)=c("Africa", "America")
rownames(tabla)=c("si", "no")


mosaicplot(tabla, cex = 1.1, col = c(c1,c3,c4), main = "Proyectos aprobados sistema alimentario")

```

Fuente : Ejemplo simulado para fines académicos

</center>

</br></br>

<!-- |           |   $y =1$      |  $y=0$         |  total           | -->
<!-- |:---------:|:-------------:|:--------------:|:----------------:| -->
<!-- | $x = 1$   |  $n_{11}$     | $n_{10}$       |  $n_{1*}$        | -->
<!-- | $x =0$    |  $n_{01}$     | $n_{00}$       |  $n_{0*}$        | -->
<!-- | **total** |  $n_{*1}$     | $n_{*0}$       |   $n$            | -->



</br></br>

### **Coeficiente Phi**

</br>

```{r, echo=FALSE, out.width="60%", fig.align = "center"}
knitr::include_graphics("img/tabla.png")
```

$$\phi = \dfrac{n_{11}\hspace{.1cm}n_{00}-n_{10}\hspace{.1cm}n_{01}}{\sqrt{n_{1*}\hspace{.1cm}n_{0*}\hspace{.1cm}n_{*0}\hspace{.1cm}n_{*1}}}$$

* Se aplica a tablas de contingencia 2x2

* Si los elementos estan concentrados en la diagonal de la tabla de contingencia, su valor será positivo, mientras que si se salen de esta diagonal su valor será negativo.

* Está relacionado con el estadístico chi-cuadrado de las tablas de contingencia 2x2. $\phi = \sqrt{\chi^2/n}$

</br></br>

### **Coeficiente V de Cramer**

</br>

Mide la inensidad de la relación entre dos variables categóricas 

* Es debil para valores inferiores a $0.2$ 
* Moderado para valores entre $0.2$ y $0.6$
* Es fuerte para valores superiores a $0.6$

$$V = \sqrt{\dfrac{\chi^2}{n(k-1)}}$$

Donde :

$n$ : total de observaciones en la tabla
$k$ : menor valor entre el número de filas menos 1 y el número de columnas menos 1


* Volor de cero indica que no hay relación entre las variables
* Valor de uno indica que existe una relación perfecta
* Valores entre 0.6 y 1 , indica que existe una relación fuerte entre las variables

</br></br>

```{r, eval=FALSE}

# install.packages("DescTools")
library(DescTools)
cat("Coeficiente Phi : ", Phi(tabla), "\n") 
cat("Coeficiente V de Cramer :", CramerV(tabla)) 
```

</br></br>

<pre>
Coeficiente Phi         :  0.3643192 
Coeficiente V de Cramer : 0.3643192
</pre>

Estos coeficientes varia entre $-1$  y $1$,  en este caso presentan un nivel bajo en  relación entre las variables.



